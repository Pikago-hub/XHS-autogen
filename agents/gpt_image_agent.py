import os
import time
import base64
import requests
import json
from typing import Annotated
from openai import OpenAI
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.base import Handoff

class GPT4oImageAgent:
    def __init__(self, model_client):
        self.model_client = model_client
        self.openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # Define the image generation tool
        async def generate_image(
            prompt: Annotated[str, "The detailed image prompt text for image generation (can be JSON or plain text)"]
        ) -> str:
            """Generate an image using gpt-image-1 via OpenAI Images API."""
            try:
                print(f"\nTOOL EXECUTION: Generating image with gpt-image-1...")
                
                # Parse JSON format if provided
                final_prompt = prompt
                try:
                    prompt_data = json.loads(prompt)
                    if isinstance(prompt_data, dict):
                        # Construct a comprehensive prompt from the structured data
                        components = []
                        
                        # Build the prompt in a specific order for best results
                        if 'Subject' in prompt_data:
                            components.append(prompt_data['Subject'])
                        
                        if 'Context' in prompt_data:
                            components.append(f"in {prompt_data['Context']}")
                        
                        if 'Composition' in prompt_data:
                            components.append(prompt_data['Composition'])
                        
                        if 'Style' in prompt_data:
                            components.append(f"{prompt_data['Style']} style")
                        
                        if 'Lighting' in prompt_data:
                            components.append(f"with {prompt_data['Lighting']}")
                        
                        if 'Color' in prompt_data:
                            components.append(f"{prompt_data['Color']} color palette")
                        
                        if 'Mood' in prompt_data:
                            components.append(f"creating a {prompt_data['Mood']} mood")
                        
                        if 'Details' in prompt_data:
                            components.append(prompt_data['Details'])
                        
                        final_prompt = ", ".join(components)
                        print(f"Parsed structured prompt format")
                except json.JSONDecodeError:
                    print(f"Using direct prompt format")
                
                print(f"Final prompt: {final_prompt[:150]}...")
                
                response = self.openai_client.images.generate(
                    model="gpt-image-1",
                    prompt=final_prompt,
                    n=1,
                    size="1024x1024",
                )
                
                if response.data and len(response.data) > 0:
                    image_base64 = response.data[0].b64_json
                    timestamp = int(time.time())
                    filename = f"gpt_image_{timestamp}.png"
                    
                    print(f"Saving generated image...")
                    with open(filename, "wb") as f:
                        f.write(base64.b64decode(image_base64))
                    
                    print(f"Image saved: {filename}")
                    
                    return f"""IMAGE_GENERATED: GPT Image created!

Filename: {filename}
Model: gpt-image-1
Format: Generated by gpt-image-1
Generation time: ~10 seconds
Location: {os.path.abspath(filename)}

Image generated successfully using gpt-image-1."""
                else:
                    return f"No image data found in response - WORKFLOW COMPLETE"
                    
            except Exception as e:
                error_msg = str(e)
                if "api_key" in error_msg.lower():
                    return "OpenAI API key not found or invalid. Please check OPENAI_API_KEY in .env - WORKFLOW COMPLETE"
                else:
                    return f"gpt-image-1 generation failed: {error_msg} - WORKFLOW COMPLETE"
        
        # Create the agent
        self.agent = AssistantAgent(
            name="gpt_image_agent",
            model_client=model_client,
            tools=[generate_image],
            system_message="""You are the gpt-image-1 generation agent.

CRITICAL: You MUST ONLY respond when you receive a detailed image prompt (either JSON format or descriptive text).
If the message contains "SKIP", "User selected Seedance", or mentions video, respond with "SKIP" and nothing else.
If no image prompt is present, respond with "SKIP" and nothing else.

When you receive an approved image prompt:
1. Check if it's in JSON format (starts with { and ends with })
2. Pass the entire prompt (JSON or text) directly to the generate_image tool
3. The tool will handle parsing JSON if needed
4. Return the result

IMPORTANT: You MUST use the generate_image tool. Do not modify or parse the prompt yourself - pass it directly to the tool.""",
            handoffs=[
                Handoff(
                    target="rednote_publisher",
                    name="post_to_rednote",
                    message="Image generated. Ready to post to RedNote."
                )
            ]
        )